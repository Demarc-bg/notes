# 数据挖掘

## K-means

### K-means两个步骤：

-  先假设K个点（称为质心），输入X = {(x1,y1),(x2,y2),...,(xN,yN)}



1. 分别计算 arg min (foreach i in X : 欧式距离(X1-K) )  

   并把输入点Xi 归类为K点

2. 分别将K个类内的点（欧式距离）求平均点

   并将更新该点为当前类的 K点

3. 一直迭代步骤1 2 直至收敛

这个算法是完全收敛的，步骤1 2 是通过不同方式降低输入点到质心的距离， 

步骤1经过步骤2的再次计算平均点更新每个K点内的归属input点

步骤2经过再归类之后再次计算平均点，提供更新归类input点之后的K平均点

> ![屏幕快照 2018-11-25 下午4.48.21](/Users/Teds/info/Bear/pic/屏幕快照 2018-11-25 下午4.48.21.png)
>
>   J函数表示每个样本点到其质心的距离平方和。K-means是要将J调整到最小。假设当前J没有达到最小值，那么首先可以固定每个类的质心uj，调整每个样例的所属的类别c(i)来让J函数减少，同样，固定c(i)，调整每个类的质心uj也可以使J减小。这两个过程就是内循环中使J单调递减的过程。当J递减到最小时，u和c也同时收敛。（在理论上，可以有多组不同的u和c值能够使得J取得最小值，但这种现象实际上很少见）。
>
> ​     由于畸变函数J是非凸函数，意味着我们不能保证取得的最小值是全局最小值，也就是说k-means对质心初始位置的选取比较感冒，但一般情况下k-means达到的局部最优已经满足需求。但如果你怕陷入局部最优，那么可以选取不同的初始值跑多遍k-means，然后取其中最小的J对应的u和c输出。

